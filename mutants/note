What happens if you run a workload without loading?
- "workload a" gets "read-failed". It's okay.
- "workload d" gets "read-failed" too. TODO: I wonder if I should modify this,
	or it's only for the initial few records.
	- When you increase the number of requests, you get less read failed ratios.
		 10,000 reqs: 2426 "read-failed"s
		100,000 reqs: 7031 "read-failed"s
	- As time goes by, you get less of them, which suggests they read some of the
		latest records.
		10 sec:  11240 operations; 1124   current ops/sec; READ-FAILED: Count=2616
		20 sec:  23106 operations; 1186.6 current ops/sec; READ-FAILED: Count=1209
		30 sec:  34990 operations; 1188.4 current ops/sec; READ-FAILED: Count= 819
		40 sec:  46873 operations; 1188.3 current ops/sec; READ-FAILED: Count= 661
		50 sec:  58744 operations; 1187.1 current ops/sec; READ-FAILED: Count= 492
		60 sec:  71300 operations; 1255.6 current ops/sec; READ-FAILED: Count= 462
		70 sec:  83244 operations; 1194.4 current ops/sec; READ-FAILED: Count= 366
		80 sec:  95109 operations; 1186.5 current ops/sec; READ-FAILED: Count= 301
		86 sec: 100000 operations;  810.3 current ops/sec; READ-FAILED: Count= 105
	- If you load the table with "recordcount = 1000", you don't get any READ-FAILED.
	- TODO: which parameter controls the behavior? This one? Look into the code.
		recordcount   =  1000
		operationcount=100000

TODO: I wonder what it reads exactly. Time to look into the code.

TODO: Make sure "read latest" simulates Facebook's workload pattern.
- Look into the code.
- The configuration file doesn't have any zipian parameters for read popularity
	of objects.





















TODO: What does the measurement do? Something useful that I can use?
- core/src/main/java/com/yahoo/ycsb/measurements/*

TODO: Plot read and write latencies for different throughputs

TODO: How to trace the cql statements that the Cassandra server serves?
- This might be a close thing
  - https://www.ibm.com/support/knowledgecenter/SS3JSW_5.2.0/com.ibm.help.gdha_reference.doc/com.ibm.help.gdha_troubleshooting.doc/gdha_enabling_tracing.html
- Another idea is to look for the source code and figure out where to insert
	the statement. I think this is what I did during the development.

-------------------------------------------------------------------------------

YCSB Build:
- mvn -pl com.yahoo.ycsb:cassandra-binding -am clean package -DskipTests
- Disabled the annoying checkstyle errors.

ycsb workloade d generates data on the fly.

nodetool drain seems to dump MemTable to a SSTable. You can measure the size
easily that way.  It doesn't seem to accecpt any new connections after that.

What's the network connection like between the client and the server nodes?
- Latency. ping.
	10 packets transmitted, 10 received, 0% packet loss, time 9000ms
	rtt min/avg/max/mdev = 0.412/0.458/0.496/0.028 ms
- Throughput. iperf. 1 Gbits/sec. Very stable.
- Network hops?
	traceroute from the client to the server.
		client: 54.221.47.168  10.153.161.184
		server: 54.145.43.45   10.153.211.52
	Interesting.
	- The route is pretty long.
	- I don't see any prefix of either the client or the server on the route.
	$ traceroute `cat ~/work/mutants/.run/cassandra-server-ips`
		traceroute to 54.145.43.45 (54.145.43.45), 30 hops max, 60 byte packets
		1  100.99.245.193 (100.99.245.193)  0.714 ms  1.006 ms  1.304 ms
		2  100.88.73.5 (100.88.73.5)  0.404 ms 100.88.73.10 (100.88.73.10)  0.418 ms 100.88.73.2 (100.88.73.2)  0.460 ms
		3  100.88.73.35 (100.88.73.35)  0.402 ms 100.88.73.41 (100.88.73.41)  0.394 ms 100.88.73.46 (100.88.73.46)  0.419 ms
		4  * * *
		5  100.92.134.195 (100.92.134.195)  0.323 ms 100.92.134.192 (100.92.134.192)  0.309 ms 100.92.134.32 (100.92.134.32)  0.291 ms
		6  100.92.134.18 (100.92.134.18)  0.300 ms 100.92.134.59 (100.92.134.59)  0.256 ms 100.92.134.208 (100.92.134.208)  0.284 ms
		7  100.92.133.12 (100.92.133.12)  0.271 ms 100.92.133.110 (100.92.133.110)  0.238 ms 100.92.133.248 (100.92.133.248)  0.254 ms
		8  100.92.134.155 (100.92.134.155)  0.243 ms 100.92.134.157 (100.92.134.157)  0.281 ms 100.92.134.152 (100.92.134.152)  0.239 ms
		9  100.92.134.128 (100.92.134.128)  0.358 ms 100.92.134.134 (100.92.134.134)  0.325 ms 100.92.134.141 (100.92.134.141)  0.273 ms
		10  100.92.128.132 (100.92.128.132)  0.345 ms 100.92.128.143 (100.92.128.143)  0.368 ms 100.92.128.139 (100.92.128.139)  0.324 ms
		11  100.92.128.144 (100.92.128.144)  0.337 ms 100.92.128.157 (100.92.128.157)  0.346 ms 100.92.128.153 (100.92.128.153)  0.355 ms
		12  100.92.132.235 (100.92.132.235)  0.382 ms 100.92.132.80 (100.92.132.80)  0.435 ms 100.92.132.245 (100.92.132.245)  0.352 ms
		13  100.92.128.221 (100.92.128.221)  0.382 ms 100.92.128.189 (100.92.128.189)  0.422 ms 100.92.128.177 (100.92.128.177)  0.381 ms
		14  100.92.128.163 (100.92.128.163)  0.354 ms 100.92.128.197 (100.92.128.197)  0.418 ms 100.92.128.164 (100.92.128.164)  0.354 ms
		15  100.92.240.67 (100.92.240.67)  17.670 ms 100.92.240.87 (100.92.240.87)  17.122 ms 100.92.240.139 (100.92.240.139)  15.880 ms
		16  216.182.224.114 (216.182.224.114)  19.554 ms 216.182.224.96 (216.182.224.96)  17.339 ms 216.182.224.114 (216.182.224.114)  19.513 ms
		17  ec2-54-145-43-45.compute-1.amazonaws.com (54.145.43.45)  0.430 ms  0.430 ms  0.424 ms

What is a good level of concurrency? how many threads? As long as you use the
same number for the unmodified Cassandra and Mutants, you should be fine.

How long do you want to run the workload? Long enough that multiple SSTables
are generated.
